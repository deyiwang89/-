### 8.1 个体与集成
- 集成学习的很多理论研究都是针对弱学习器进行的, 而基学习器有时也被称为弱学习器.
- 集成学习的结果通过投票法(voting)产生, 即"少数服从多数".
```math
\begin{aligned} P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) &=\sum_{k=0}^{\lfloor T / 2\rfloor} \left( \begin{array}{c}{T} \\ {k}\end{array}\right)(1-\epsilon)^{k} \epsilon^{T-k} \\ & \leqslant \exp \left(-\frac{1}{2} T(1-2 \epsilon)^{2}\right) \end{aligned}
\tag{8.3}
```
[推导]:由基分类器相互独立，设X为T个基分类器分类正确的次数，因此`$\mathrm{X} \sim \mathrm{B}(\mathrm{T}, 1-\mathrm{\epsilon})$`
```math
\begin{aligned} P(H(x) \neq f(x))=& P(X \leq\lfloor T / 2\rfloor) \\ & \leqslant P(X \leq T / 2)
\\ & =P\left[X-(1-\varepsilon) T \leqslant \frac{T}{2}-(1-\varepsilon) T\right] 
\\ & =P\left[X-
(1-\varepsilon) T \leqslant -\frac{T}{2}\left(1-2\varepsilon\right)]\right]
 \end{aligned}
```
根据Hoeffding不等式`$P(X-(1-\epsilon)T\leqslant -kT) \leq \exp (-2k^2T)$`
令`$k=\frac {(1-2\epsilon)}{2}$`得
```math
\begin{aligned} P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) &=\sum_{k=0}^{\lfloor T / 2\rfloor} \left( \begin{array}{c}{T} \\ {k}\end{array}\right)(1-\epsilon)^{k} \epsilon^{T-k} \\ & \leqslant \exp \left(-\frac{1}{2} T(1-2 \epsilon)^{2}\right) \end{aligned}
\tag{8.3}
```
根据个体学习器的生成方式, 目前的集成学习方法大致可分为两大类, 即
个体学习器问存在强依赖关系、必须串行生成的序列化方法, 以及个体学习器
间不存在强依赖关系、可同时生成的并行化方法;前者的代表是Boosting, 后
者的代表是Bagging 和"随机森林" (Random Forest).
### 8.2 Boosting
Boosting 是一族可将弱学习器提升为强学习器的算法.这族算法的工作机
制类似:先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练
样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，
然后基于调整后的样本分布来训练下一个基学习器;如此重复进行，直至基学
习器数目达到事先指定的值T ， 最终将这T 个基学习器进行加权结合.
下面介绍Adaboost算法, 可以将其理解为其实基学习器的线性组合:

```math
H(\boldsymbol{x})=\sum_{t=1}^{T} \alpha_{t} h_{t}(\boldsymbol{x})
\tag{8.4}
```

又由式(8.11)可知
```math
\alpha_{t}=\frac{1}{2} \ln \left(\frac{1-\epsilon_{t}}{\epsilon_{t}}\right)
```
该分类器的权重只与分类器的错误率负相关(即错误率越大，权重越低)

1. 先考虑指数损失函数`$e^{-f(x) H(x)}$`的含义：`$f$`为真实函数，对于样本`$x$`来说，`$f(\boldsymbol{x}) \in\{-1,+1\}$`只能取和两个值，而`$H(\boldsymbol{x})$`是一个实数；
当`$H(\boldsymbol{x})$`的符号与`$f(x)$`一致时，`$f(\boldsymbol{x}) H(\boldsymbol{x})>0$`，因此`$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}=e^{-|H(\boldsymbol{x})|}<1$`，且`$|H(\boldsymbol{x})|$`越大指数损失函数`$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}$`越小（这很合理：此时`$|H(\boldsymbol{x})|$`越大意味着分类器本身对预测结果的信心越大，损失应该越小；若`$|H(\boldsymbol{x})|$`在零附近，虽然预测正确，但表示分类器本身对预测结果信心很小，损失应该较大）；
当`$H(\boldsymbol{x})$`的符号与`$f(\boldsymbol{x})$`不一致时，`$f(\boldsymbol{x}) H(\boldsymbol{x})<0$`，因此`$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}=e^{|H(\boldsymbol{x})|}>1$`，且`$| H(\boldsymbol{x}) |$`越大指数损失函数越大（这很合理：此时`$| H(\boldsymbol{x}) |$`越大意味着分类器本身对预测结果的信心越大，但预测结果是错的，因此损失应该越大；若`$| H(\boldsymbol{x}) |$`在零附近，虽然预测错误，但表示分类器本身对预测结果信心很小，虽然错了，损失应该较小）；
2. 符号`$\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}[\cdot]$`的含义：`$\mathcal{D}$`为概率分布，可简单理解为在数据集`$D$`中进行一次随机抽样，每个样本被取到的概率；`$\mathbb{E}[\cdot]$`为经典的期望，则综合起来`$\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}[\cdot]$`表示在概率分布`$\mathcal{D}$`上的期望，可简单理解为对数据集`$D$`以概率`$\mathcal{D}$`进行加权后的期望。
```math
\begin{aligned}
\ell_{\mathrm{exp}}(H | \mathcal{D})=&\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}\right]
\\ =&P(f(x)=1|x)*e^{-H(x)}+P(f(x)=-1|x)*e^{H(x)}
\end{aligned}
```

由于`$P(f(x)=1|x)和P(f(x)=-1|x)$`为常数

故式(8.6)可轻易推知

```math
\frac{\partial \ell_{\exp }(H | \mathcal{D})}{\partial H(\boldsymbol{x})}=-e^{-H(\boldsymbol{x})} P(f(\boldsymbol{x})=1 | \boldsymbol{x})+e^{H(\boldsymbol{x})} P(f(\boldsymbol{x})=-1 | \boldsymbol{x})
\tag{8.6}
```

令式(8.6)等于0可得

式(8.7)
```math
H(\boldsymbol{x})=\frac{1}{2} \ln \frac{P(f(x)=1 | \boldsymbol{x})}{P(f(x)=-1 | \boldsymbol{x})}
\tag{8.7}
```
式(8.8)显然成立
```math
\begin{aligned}
\operatorname{sign}(H(\boldsymbol{x}))&=\operatorname{sign}\left(\frac{1}{2} \ln \frac{P(f(x)=1 | \boldsymbol{x})}{P(f(x)=-1 | \boldsymbol{x})}\right)
\\ & =\left\{\begin{array}{ll}{1,} & {P(f(x)=1 | \boldsymbol{x})>P(f(x)=-1 | \boldsymbol{x})} \\ {-1,} & {P(f(x)=1 | \boldsymbol{x})<P(f(x)=-1 | \boldsymbol{x})}\end{array}\right.
\\ & =\underset{y \in\{-1,1\}}{\arg \max } P(f(x)=y | \boldsymbol{x})
\end{aligned}
\tag{8.8}
```



```math
\begin{aligned} h_{t}(\boldsymbol{x}) &=\underset{h}{\arg \max } \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[\frac{e^{-f(\boldsymbol{x}) H_{t-1}(\boldsymbol{x})}}{\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[e^{-f(\boldsymbol{x}) H_{t-1}(\boldsymbol{x})}\right]} f(\boldsymbol{x}) h(\boldsymbol{x})\right] \\ &=\underset{\boldsymbol{h}}{\arg \max } \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}_{t}}[f(\boldsymbol{x}) h(\boldsymbol{x})] \end{aligned}
\tag{8.16}
```
[推导]：
假设x的概率分布是f(x)
(注:本书中概率分布全都是`$\mathcal{D(x)}$`)

```math
\mathbb{E(g(x))}=\sum_{i=1}^{|D|}f(x)g(x)
```
故可得

```math
\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}\right]=\sum_{i=1}^{|D|} \mathcal{D}\left(\boldsymbol{x}_{i}\right) e^{-f\left(\boldsymbol{x}_{i}\right) H\left(\boldsymbol{x}_{i}\right)}
```
由式(8.15)可知
```math
\mathcal{D}_{t}\left(\boldsymbol{x}_{i}\right)=\mathcal{D}\left(\boldsymbol{x}_{i}\right) \frac{e^{-f\left(\boldsymbol{x}_{i}\right) H_{t-1}\left(\boldsymbol{x}_{i}\right)}}{\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[e^{-f(\boldsymbol{x}) H_{t-1}(\boldsymbol{x})}\right]}
```

所以式(8.16)可以表示为
```math
\begin{aligned} & \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[\frac{e^{-f(\boldsymbol{x}) H_{t-1}(\boldsymbol{x})}}{\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[e^{-f(\boldsymbol{x}) H_{t-1}(\boldsymbol{x})}\right]} f(\boldsymbol{x}) h(\boldsymbol{x})\right] \\=& \sum_{i=1}^{|D|} \mathcal{D}\left(\boldsymbol{x}_{i}\right) \frac{e^{-f\left(\boldsymbol{x}_{i}\right) H_{t-1}\left(\boldsymbol{x}_{i}\right)}}{\mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}}\left[e^{-f(\boldsymbol{x}) H_{t-1}(\boldsymbol{x}) }]  \right.}f(x_i)h(x_i) \\=& \sum_{i=1}^{|D|} \mathcal{D}_{t}\left(\boldsymbol{x}_{i}\right) f\left(\boldsymbol{x}_{i}\right) h\left(\boldsymbol{x}_{i}\right) \\=& \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}_{t}}[f(\boldsymbol{x}) h(\boldsymbol{x})] \end{aligned}
```

【注】：由下式`$(*)$`也可推至式(8.16)

```math
P(f(x)=1|x)e^{-H(x)}+P(f(x)=-1|x)e^{H(x)}(*)
```

首先式$(*)$可以拆成n个式子,n的个数为x的取值个数


```math
P(f(x_i)=1|x_i)e^{-H(x_i)}+P(f(x_i)=-1|x_i)e^{H(x_i)}(i=1,2,...,n)(**)
```

当`$x_i$`确定的时候
`$P(f(x_i=1|x_i))$`与`$P(f(x_i=-1|x_i))$`
其中有一个为0，另一个为1

则式`$(**)$`可以化简成
```math
e^{-f(x_i)H(x_i)}(i=1,2,...,n)(***)
```

拆成n个式子是根据不同的x来拆分的，可以把`$x=x_i$`看成一个事件，设为事件`$A_i$`。

当事件`$A_i$`发生时，事件`$A_j$`一定不发生，即各事件互斥,而且各个事件发生的概率是`$P(A_i)=\mathcal{D}(x_i)$`

此时可以考虑成原来的x被分成了n叉树，每个路径的概率是`$\mathcal{D}(x_i)$`,叶子结点的值是`$e^{-f(x_i)H(x_i)}$`相乘再相加即为期望，同式(8.16)

### 8.3 Bagging与随机森林

[关于算法时间复杂度的介绍](https://blog.csdn.net/com_ice/article/details/79025117)

以下内容来自[ 路飞的纯白世界的博客: ](https://blog.csdn.net/u010921136/article/details/90441104)

- 个体与集成
集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务，又是也被称为多分类器系统、基于委员会的学习

然而并不是只有多分类任务才会用到集成学习，二分类任务也可以通过集成学习来产生多个预测结果，并通过投票法产生最终预测结果。对于回归任务则可采用平均法产生出最终预测结果

- 集成策略有两种：

同质集成：由多个相同类型的个体学习器组成，其中的个体学习器称为基学习器、相应的学习算法称为基学习算法。
异质集成：由多个不同类型的个体学习器组成，其中的个体学习器称为组件学习器，或者直接称为个体学习器。

希望获得比单一学习器更好的性能，多个个体学习器应当要有一定的准确性，以及要有多样性，否则集成学习可能会不起作用，甚至起负作用
如果有奇数个分类器，超过一半分类正确，则集成分类就正确

如果基分类器的错误率相互独立，随着个体分类器数目T的增大，集成的错误率将指数下降，最终趋近于0
然而现实中，它们显然不可能相互独立，事实上，个体学习器的准确性和多样性本身就存在冲突
一般的，准确性提高后，要增加多样性就需要牺牲准确性

- 目前的集成学习方法大致分为两类：
  - 个体学习器间存在强依赖关系、必须串行生成的序列化方法。如：Boosting
  -  个体学习器间不存在强依赖关系、可同时生成的并行化方法。如：Bagging和随机森林

- Boosting
Boosting是一族可将弱学习器提升为强学习器的算法，工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。可以看出，这是串行的训练方式。

- 重赋权法：在训练过程的每一轮中，根据样本分布为每个训练样本重新赋予一个权重。
重采样法：对无法接受带权样本的基学习算法，可通过重采样法处理，即在每一轮学习中，根据样本分布对训练集重新进行采样，再用重采样而得的样本集对基学习器进行训练，

Boosting族算法最著名的代表是AdaBoost，只适用于二分类任务。
一旦分类器准确率低于50%（随机猜测），则抛弃该学习器，甚至停止学习过程。
这时，我们采用重采样法可获得重启动机会，以避免过早停止训练过程。
Boosting主要关注降低偏差。

- Bagging与随机森林
Bagging训练的基本流程是：利用自助采样法，采样出T个包含m个训练样本的采样集（约占初始训练集的63.2%，每个采样集都互有交叠，但同时也互有差异，保证了基学习器具有一定的独立性），然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。这T个基学习器可同时并行的进行训练。
Bagging能不经修改地用于多分类和回归等任务。
Bagging主要关注降低方差。

随机森林（Random Forest：RF）是Bagging的一个扩展变体：以决策树为基学习器构建Bagging的基础上，进一步在训练过程中引入了随机属性选择。具体来说，传统决策树是在当前结点中的d个属性中选择最优的属性进行划分，而RF是在这其中随机选择k个属性，再选择最优的一个用于划分。如果k=1，就是随机选择一个属性进行划分，如果k=d则和传统决策树相同，一般情况，推荐值k=log2d

随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动
并且由于划分考察的是随机的属性子集，因此训练效率常由于Bagging（属性全集）

- 结合策略
学习器结合有三个好处：
1、统计方面：提高泛化性能
2、计算方面：降低陷入糟糕局部极小点的风险
3、表示方面：假设空间有所扩大，有可能学得更好的近似

- 简单平均法：简单平均
   -  加权平均法：通过训练学习而得权重，未必一定优于简单平均
   -  绝对多数投票法：得票数过半的标记则预测为该标记，否则拒绝预测（如果没有此约束，则退化为相对多数投票法）
   -  相对多数投票法：得票数最多的标记，若同时多个获得最高票，则随机选一个
   -  加权投票法：通过训练学习而得权重
- 学习法：通过另一个学习器来进行结合，这里我们把个体学习器成为初级学习器，用于结合的学习器称为次级学习器或者元学习器

**Stacking** 是学习法的代表，先从初始数据集训练出初级学习器，然后“生成”一个新数据集用于训练初级学习器。这个新数据集中，初级学习器的输出被当作样例的输入特征，而初始样本的标记仍被当作样例标记

**贝叶斯模型平均（BMA）** 也是一种学习法，基于后验概率来为不同模型赋予权重
Stacking通常优于BMA，因为其鲁棒性比BMA好，而且BMA对模型近似误差非常敏感

不同学习器的输出类型可能不同，分为两类：
类标记：预测为某类则取值为1，否则为0，使用类标记的投票也称为硬投票
类概率：对后验概率的一个估计，使用类概率的投票也称为软投票
不同输出类型不能混用，需要某种转换后再进行投票

- 多样性
误差-分歧分解理论上解释了个体学习器准确性越高、多样性越大则集成越好
多样性度量：估算多样化程度，典型做法是考虑个体分类器的两两相似/不相似性
多样性增强：数据样本扰动、输入属性扰动、输出表示扰动、算法参数扰动

